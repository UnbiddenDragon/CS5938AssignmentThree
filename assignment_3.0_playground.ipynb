{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "%load_ext autotime",
   "id": "810eb47f572d6c5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Instructions\n",
    "1. Seek to improve the one-layer model by changing the internal activation function. This will involve changing A1 to something else, and also changing the derivative involving one or both of dAI and dZ1.\n",
    "2. Add another layer with your choice of activation function (other than the logistic function) and your choice of internal nodes\n",
    "3. Add a third layer\n",
    "4. Add a fourth layer\n",
    "5. Report on your choices and assessment of the resulting models - you can extend the basic model assessment tools supplied\n",
    "6. Based on your answers to tasks 1-4, write code that - for this dataset - allows a user to build and run a neural net with a high degree of flexibility in terms of architecture and hyperperameter choices.\n",
    "7. Explain how advanced optimisers (e.g. Adam) would extend your code"
   ],
   "id": "aa40c179c7415f24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:06:27.022965Z",
     "start_time": "2025-08-15T09:06:26.595822Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ],
   "id": "9cc272dfe3c75cef",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:06:28.579639Z",
     "start_time": "2025-08-15T09:06:28.566036Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import the Dataset\n",
    "\n",
    "df = pd.read_csv ('flower2D.csv')\n",
    "print(df.shape)\n",
    "print(df.info())\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "df.head()"
   ],
   "id": "146071f5ff35bd6d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  400 non-null    int64  \n",
      " 1   X1          400 non-null    float64\n",
      " 2   X2          400 non-null    float64\n",
      " 3   Y           400 non-null    int64  \n",
      "dtypes: float64(2), int64(2)\n",
      "memory usage: 12.6 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         X1        X2  Y\n",
       "0  0.005257 -0.303586  0\n",
       "1  0.996098  3.461645  0\n",
       "2  0.384404  2.392678  0\n",
       "3  0.951043  3.282709  0\n",
       "4  0.091932  1.066689  0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.005257</td>\n",
       "      <td>-0.303586</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.996098</td>\n",
       "      <td>3.461645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.384404</td>\n",
       "      <td>2.392678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.951043</td>\n",
       "      <td>3.282709</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.091932</td>\n",
       "      <td>1.066689</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:22:19.791275Z",
     "start_time": "2025-08-15T09:22:19.787262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = df[[\"X1\",\"X2\"]], np.array(df[\"Y\"])\n",
    "n = 300\n",
    "n_test = X.shape[0] - n\n",
    "X_train, X_test = X[:n].values, X[n:].values       # shape (300, 2) and (n_test, 2)\n",
    "y_train, y_test = y[:n].reshape(-1,1), y[n:].reshape(-1,1)  # shape (300,1)"
   ],
   "id": "e52261f4c1f9830c",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Loss & functions",
   "id": "4d955c0d8fa665a2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:00.377365Z",
     "start_time": "2025-08-15T09:23:00.373228Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def binary_cross_entropy(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return -(1/m) * np.sum(Y * np.log(Y_hat + 1e-15) + (1 - Y) * np.log(1 - Y_hat + 1e-15))\n",
    "\n",
    "def binary_cross_entropy_grad(Y, Y_hat):\n",
    "    m = Y.shape[0]\n",
    "    return (Y_hat - Y) / m"
   ],
   "id": "61a6edcdc1a560da",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Neural network design\n",
    "#### Activation Layers"
   ],
   "id": "aae714ed5ab05258"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:00.810540Z",
     "start_time": "2025-08-15T09:23:00.806352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = 1 / (1 + np.exp(-x))\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * self.out * (1 - self.out)\n",
    "\n",
    "    def parameters_and_gradients(self):\n",
    "        return []\n",
    "\n",
    "class Relu:\n",
    "    def __init__(self):\n",
    "        self.out = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.out = np.maximum(0, x)\n",
    "        return self.out\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        return grad_output * (self.out > 0)\n",
    "\n",
    "    def parameters_and_gradients(self):\n",
    "        return []"
   ],
   "id": "8caf403ead96c26d",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Linear layer",
   "id": "cb1f387f8154fec6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:01.156921Z",
     "start_time": "2025-08-15T09:23:01.152911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Linear:\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * np.sqrt(2. / input_dim)\n",
    "        self.biases = np.zeros((1, output_dim))\n",
    "        self.input = None\n",
    "        self.grad_weights = None\n",
    "        self.grad_biases = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.input = x\n",
    "        return np.dot(x, self.weights) + self.biases\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        self.grad_weights = np.dot(self.input.T, grad_output)\n",
    "        self.grad_biases = np.sum(grad_output, axis=0, keepdims=True)\n",
    "        return np.dot(grad_output, self.weights.T)\n",
    "\n",
    "    def parameters_and_gradients(self):\n",
    "        return [(self.weights, self.grad_weights),\n",
    "                (self.biases, self.grad_biases)]"
   ],
   "id": "de007c03d10479c2",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Neural Network",
   "id": "e4838b9219bbe7f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:01.580490Z",
     "start_time": "2025-08-15T09:23:01.576426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, layers=[]):\n",
    "        self.layers = layers\n",
    "\n",
    "    def add_layer(self, layer):\n",
    "        self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        gradient_input = grad_output\n",
    "        for layer in reversed(self.layers):\n",
    "            gradient_input = layer.backward(gradient_input)\n",
    "\n",
    "    def parameters_and_gradients(self):\n",
    "        params_and_grads = []\n",
    "        for layer in self.layers:\n",
    "            params_and_grads.extend(layer.parameters_and_gradients())\n",
    "        return params_and_grads"
   ],
   "id": "38b3f8eb4ac9b615",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### No hidden layers",
   "id": "3faba4f51f7d193c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:02.233406Z",
     "start_time": "2025-08-15T09:23:02.179206Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nn = NeuralNetwork([\n",
    "    Linear(X_train.shape[1], 1),  # input_dim = n_features\n",
    "    Sigmoid()\n",
    "])\n",
    "\n",
    "learning_rate = 0.1\n",
    "num_epochs = 2000\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    # Forward pass\n",
    "    y_hat = nn.forward(X_train)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = binary_cross_entropy(y_train, y_hat)\n",
    "\n",
    "    # Backward pass\n",
    "    grad_loss = binary_cross_entropy_grad(y_train, y_hat)\n",
    "    nn.backward(grad_loss)\n",
    "\n",
    "    # Update parameters\n",
    "    for param, grad in nn.parameters_and_gradients():\n",
    "        param -= learning_rate * grad\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(f\"Iteration {i}, loss: {loss:.4f}\")\n",
    "\n",
    "for param, _ in nn.parameters_and_gradients():\n",
    "    print(param)"
   ],
   "id": "f0862f4a2dbd32",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss: 0.9440\n",
      "Iteration 200, loss: 0.6103\n",
      "Iteration 400, loss: 0.6040\n",
      "Iteration 600, loss: 0.6029\n",
      "Iteration 800, loss: 0.6026\n",
      "Iteration 1000, loss: 0.6025\n",
      "Iteration 1200, loss: 0.6025\n",
      "Iteration 1400, loss: 0.6025\n",
      "Iteration 1600, loss: 0.6025\n",
      "Iteration 1800, loss: 0.6025\n",
      "[[ 0.09949512]\n",
      " [-0.24299735]]\n",
      "[[-0.67412963]]\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:18.220896Z",
     "start_time": "2025-08-15T09:23:18.218160Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Print the learned weights and bias\n",
    "for layer in nn.layers:\n",
    "    if isinstance(layer, Linear):\n",
    "        print(\"Weights:\\n\", layer.weights)\n",
    "        print(\"Bias:\\n\", layer.biases)"
   ],
   "id": "4b98fc5f7554b057",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:\n",
      " [[ 0.09949512]\n",
      " [-0.24299735]]\n",
      "Bias:\n",
      " [[-0.67412963]]\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-15T09:23:27.430571Z",
     "start_time": "2025-08-15T09:23:27.425344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "y_hat_test = nn.forward(X_test)\n",
    "\n",
    "\n",
    "predictions = (y_hat_test > 0.5).astype(int)\n",
    "labels = (y_test > 0.5).astype(int)\n",
    "\n",
    "\n",
    "predictions = predictions.flatten()\n",
    "labels = labels.flatten()\n",
    "\n",
    "\n",
    "tp = np.sum((predictions == 1) & (labels == 1))\n",
    "tn = np.sum((predictions == 0) & (labels == 0))\n",
    "fp = np.sum((predictions == 1) & (labels == 0))\n",
    "fn = np.sum((predictions == 0) & (labels == 1))\n",
    "\n",
    "\n",
    "cm = np.array([[tn, fp],\n",
    "               [fn, tp]])\n",
    "\n",
    "print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "\n",
    "model_score = (tn + tp) / (tn + fp + fn + tp)\n",
    "print(\"Model score:\", model_score)"
   ],
   "id": "889d3f48b532f50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[ 0  0]\n",
      " [72 28]]\n",
      "Model score: 0.28\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41ae4341ea6b2487"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
